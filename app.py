import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
import os
import json
from datetime import datetime
import io
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill
from reportlab.lib.pagesizes import letter, A4
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, PageBreak
from reportlab.lib.units import inch
import sqlalchemy
from sqlalchemy import create_engine, text

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except (ImportError, OSError):
    LIGHTGBM_AVAILABLE = False
    lgb = None

# è¨­å®šç’°å¢ƒè®Šæ•¸ä»¥éš±è— TensorFlow GPU è­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # åªé¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # ç¦ç”¨ GPU

from tensorflow import keras
from tensorflow.keras import layers
import warnings
warnings.filterwarnings('ignore')

# è³‡æ–™åº«é€£æ¥
DATABASE_URL = os.getenv('DATABASE_URL')
if DATABASE_URL:
    engine = create_engine(DATABASE_URL)
else:
    engine = None

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="è‚¡å¸‚æ”¶ç›¤åƒ¹é æ¸¬ç³»çµ±",
    page_icon="ğŸ“ˆ",
    layout="wide"
)

# åˆå§‹åŒ– session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'prediction_cols' not in st.session_state:
    st.session_state.prediction_cols = []
if 'close_col' not in st.session_state:
    st.session_state.close_col = None
if 'manual_override' not in st.session_state:
    st.session_state.manual_override = False
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False
if 'trained_models' not in st.session_state:
    st.session_state.trained_models = {}
if 'model_results' not in st.session_state:
    st.session_state.model_results = {}
if 'feature_engineered_data' not in st.session_state:
    st.session_state.feature_engineered_data = None

# æ¨™é¡Œ
st.title("ğŸ“ˆ è‚¡å¸‚æ”¶ç›¤åƒ¹é æ¸¬ç³»çµ±")
st.markdown("---")

# å´é‚Šæ¬„
with st.sidebar:
    st.header("ğŸ“ æ•¸æ“šä¸Šå‚³")
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³æ‚¨çš„æ•¸æ“šæª”æ¡ˆ (CSV æˆ– TXT)",
        type=['csv', 'txt'],
        help="æª”æ¡ˆæ ¼å¼ï¼šæ—¥æœŸ,æ™‚é–“,é–‹ç›¤åƒ¹,æœ€é«˜åƒ¹,æœ€ä½åƒ¹,æ”¶ç›¤åƒ¹,æˆäº¤é‡,é æ¸¬1,é æ¸¬2,...,é æ¸¬10"
    )
    
    st.markdown("---")
    st.header("ğŸ“Š åŠŸèƒ½é¸å–®")
    page = st.radio(
        "é¸æ“‡åŠŸèƒ½",
        ["æ•¸æ“šåˆ†æèˆ‡æ¨¡å‹è¨“ç·´", "æ¨¡å‹æ¯”è¼ƒ", "æ­·å²è¨˜éŒ„", "ç‰¹å¾µå·¥ç¨‹", "åŒ¯å‡ºå ±å‘Š"],
        index=0
    )
    
    st.markdown("---")
    st.header("âš™ï¸ ç³»çµ±è¨­å®š")

# å‡½æ•¸ï¼šè®€å–ä¸¦è§£ææ•¸æ“š
def load_data(file):
    """æ™ºæ…§å‹è®€å–æ•¸æ“šä¸¦è‡ªå‹•è­˜åˆ¥æ¬„ä½"""
    # å˜—è©¦å¤šç¨®ç·¨ç¢¼æ–¹å¼ï¼ˆåŒ…å« UTF-16 ç”¨æ–¼è™•ç† Excel åŒ¯å‡ºçš„æ–‡å­—æª”ï¼‰
    encodings = ['utf-8', 'utf-16', 'utf-16-le', 'utf-16-be', 'gbk', 'big5', 'gb2312', 'latin-1', 'iso-8859-1', 'cp1252']
    
    df = None
    last_error = None
    
    for encoding in encodings:
        try:
            file.seek(0)
            df = pd.read_csv(file, sep=None, engine='python', encoding=encoding)
            
            # é©—è­‰æ•¸æ“šæ˜¯å¦ç‚ºæ•¸å€¼å‹ï¼ˆé™¤äº†æ—¥æœŸ/æ™‚é–“æ¬„ä½ï¼‰
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) == 0:
                # å˜—è©¦è½‰æ›å¯èƒ½çš„æ•¸å€¼æ¬„ä½
                for col in df.columns:
                    if col not in ['æ—¥æœŸ', 'date', 'Date', 'æ™‚é–“', 'time', 'Time']:
                        try:
                            df[col] = pd.to_numeric(df[col], errors='coerce')
                        except:
                            pass
            
            # æˆåŠŸè®€å–ï¼Œè¿”å›æ•¸æ“š
            return df
            
        except UnicodeDecodeError as e:
            last_error = e
            continue
        except Exception as e:
            last_error = e
            continue
    
    # å¦‚æœæ‰€æœ‰ç·¨ç¢¼éƒ½å¤±æ•—ï¼Œé¡¯ç¤ºéŒ¯èª¤
    if df is None:
        st.error(f"ç„¡æ³•è®€å–æª”æ¡ˆã€‚å·²å˜—è©¦å¤šç¨®ç·¨ç¢¼æ–¹å¼ä½†éƒ½å¤±æ•—ã€‚æœ€å¾ŒéŒ¯èª¤ï¼š{str(last_error)}")
        st.info("å»ºè­°ï¼šè«‹ç¢ºä¿æ‚¨çš„æª”æ¡ˆæ˜¯æ¨™æº–çš„ CSV æˆ– TXT æ ¼å¼ï¼Œä¸”åŒ…å«æ•¸å€¼æ•¸æ“šã€‚")
        return None
    
    return df

# å‡½æ•¸ï¼šæ™ºæ…§è­˜åˆ¥æ¬„ä½
def identify_columns(df):
    """è‡ªå‹•è­˜åˆ¥æ¬„ä½çµæ§‹ä¸¦æ‰¾å‡ºé æ¸¬æ¬„ä½"""
    columns = df.columns.tolist()
    
    # åŸºæœ¬æ¬„ä½åç¨±ï¼ˆå¯èƒ½çš„è®Šé«”ï¼‰
    basic_cols = {
        'date': ['æ—¥æœŸ', 'date', 'Date', 'DATE', 'æ™‚é–“'],
        'time': ['æ™‚é–“', 'time', 'Time', 'TIME'],
        'open': ['é–‹ç›¤åƒ¹', 'open', 'Open', 'OPEN', 'é–‹ç›¤'],
        'high': ['æœ€é«˜åƒ¹', 'high', 'High', 'HIGH', 'æœ€é«˜'],
        'low': ['æœ€ä½åƒ¹', 'low', 'Low', 'LOW', 'æœ€ä½'],
        'close': ['æ”¶ç›¤åƒ¹', 'close', 'Close', 'CLOSE', 'æ”¶ç›¤'],
        'volume': ['æˆäº¤é‡', 'volume', 'Volume', 'VOLUME', 'æˆäº¤']
    }
    
    # æ‰¾å‡ºé æ¸¬æ¬„ä½
    prediction_cols = []
    for col in columns:
        # æª¢æŸ¥æ˜¯å¦åŒ…å«"é æ¸¬"æˆ–"prediction"
        if 'é æ¸¬' in str(col) or 'prediction' in str(col).lower() or 'pred' in str(col).lower():
            prediction_cols.append(col)
    
    # å¦‚æœæ²’æœ‰æ˜ç¢ºçš„é æ¸¬æ¬„ä½ï¼Œå˜—è©¦æ‰¾æ•¸å­—ç·¨è™Ÿçš„æ¬„ä½
    if not prediction_cols:
        for col in columns:
            # æª¢æŸ¥æ˜¯å¦ç‚º é æ¸¬1, é æ¸¬2 é€™é¡æ ¼å¼
            if any(char.isdigit() for char in str(col)) and 'é æ¸¬' in str(col):
                prediction_cols.append(col)
    
    return prediction_cols

# å‡½æ•¸ï¼šè¨ˆç®—ç›¸é—œæ€§
def calculate_correlations(df, target_col, feature_cols):
    """è¨ˆç®—ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸çš„ç›¸é—œæ€§"""
    correlations = {}
    p_values = {}
    
    for col in feature_cols:
        if col in df.columns:
            # ç§»é™¤ç¼ºå¤±å€¼
            valid_data = df[[col, target_col]].dropna()
            if len(valid_data) > 2:
                corr, p_val = stats.pearsonr(valid_data[col], valid_data[target_col])
                correlations[col] = corr
                p_values[col] = p_val
    
    return correlations, p_values

# å‡½æ•¸ï¼šå‰µå»ºæ™‚åºçª—å£æ•¸æ“šï¼ˆç”¨æ–¼ LSTMï¼‰
def create_sequences(X, y, time_steps=5):
    """å‰µå»º LSTM æ™‚åºçª—å£æ•¸æ“š"""
    X_seq, y_seq = [], []
    for i in range(len(X) - time_steps):
        X_seq.append(X[i:(i + time_steps)])
        y_seq.append(y[i + time_steps])
    return np.array(X_seq), np.array(y_seq)

# å‡½æ•¸ï¼šè¨ˆç®—æŠ€è¡“æŒ‡æ¨™
def calculate_technical_indicators(df, close_col, open_col=None, high_col=None, low_col=None):
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ä¸¦æ·»åŠ åˆ°æ•¸æ“šæ¡†"""
    df_enhanced = df.copy()
    
    if close_col not in df.columns:
        return df_enhanced
    
    # ç°¡å–®ç§»å‹•å¹³å‡ (SMA)
    for window in [5, 10, 20]:
        df_enhanced[f'SMA_{window}'] = df[close_col].rolling(window=window).mean()
    
    # æŒ‡æ•¸ç§»å‹•å¹³å‡ (EMA)
    for window in [5, 10, 20]:
        df_enhanced[f'EMA_{window}'] = df[close_col].ewm(span=window, adjust=False).mean()
    
    # ç›¸å°å¼·å¼±æŒ‡æ¨™ (RSI)
    delta = df[close_col].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df_enhanced['RSI_14'] = 100 - (100 / (1 + rs))
    
    # MACD
    exp1 = df[close_col].ewm(span=12, adjust=False).mean()
    exp2 = df[close_col].ewm(span=26, adjust=False).mean()
    df_enhanced['MACD'] = exp1 - exp2
    df_enhanced['MACD_Signal'] = df_enhanced['MACD'].ewm(span=9, adjust=False).mean()
    df_enhanced['MACD_Hist'] = df_enhanced['MACD'] - df_enhanced['MACD_Signal']
    
    # å¸ƒæ—é€šé“ (Bollinger Bands)
    if close_col in df.columns:
        rolling_mean = df[close_col].rolling(window=20).mean()
        rolling_std = df[close_col].rolling(window=20).std()
        df_enhanced['BB_Upper'] = rolling_mean + (rolling_std * 2)
        df_enhanced['BB_Lower'] = rolling_mean - (rolling_std * 2)
        df_enhanced['BB_Width'] = df_enhanced['BB_Upper'] - df_enhanced['BB_Lower']
    
    # æ³¢å‹•ç‡
    df_enhanced['Volatility_10'] = df[close_col].pct_change().rolling(window=10).std()
    df_enhanced['Volatility_20'] = df[close_col].pct_change().rolling(window=20).std()
    
    # å‹•é‡æŒ‡æ¨™
    df_enhanced['Momentum_5'] = df[close_col].diff(5)
    df_enhanced['Momentum_10'] = df[close_col].diff(10)
    
    # ROC (è®ŠåŒ–ç‡)
    df_enhanced['ROC_10'] = ((df[close_col] - df[close_col].shift(10)) / df[close_col].shift(10)) * 100
    
    return df_enhanced

# å‡½æ•¸ï¼šä¿å­˜é æ¸¬è¨˜éŒ„åˆ°è³‡æ–™åº«
def save_prediction_to_db(model_type, model_params, features_used, test_size, mae, rmse, r2, 
                          dataset_name, dataset_rows, predictions, feature_importance=None):
    """ä¿å­˜é æ¸¬è¨˜éŒ„åˆ°è³‡æ–™åº«"""
    if engine is None:
        return False
    
    try:
        with engine.connect() as conn:
            query = text("""
                INSERT INTO prediction_history 
                (model_type, model_params, features_used, test_size, mae, rmse, r2_score, 
                 dataset_name, dataset_rows, predictions, feature_importance)
                VALUES 
                (:model_type, :model_params, :features_used, :test_size, :mae, :rmse, :r2_score,
                 :dataset_name, :dataset_rows, :predictions, :feature_importance)
            """)
            
            conn.execute(query, {
                'model_type': model_type,
                'model_params': json.dumps(model_params),
                'features_used': features_used,
                'test_size': test_size,
                'mae': float(mae),
                'rmse': float(rmse),
                'r2_score': float(r2),
                'dataset_name': dataset_name,
                'dataset_rows': int(dataset_rows),
                'predictions': json.dumps(predictions) if predictions else None,
                'feature_importance': json.dumps(feature_importance) if feature_importance else None
            })
            conn.commit()
        return True
    except Exception as e:
        st.warning(f"ç„¡æ³•ä¿å­˜åˆ°è³‡æ–™åº«ï¼š{str(e)}")
        return False

# å‡½æ•¸ï¼šå¾è³‡æ–™åº«ç²å–æ­·å²è¨˜éŒ„
def get_prediction_history(limit=10):
    """å¾è³‡æ–™åº«ç²å–æ­·å²è¨˜éŒ„"""
    if engine is None:
        return None
    
    try:
        query = text("""
            SELECT * FROM prediction_history 
            ORDER BY created_at DESC 
            LIMIT :limit
        """)
        df = pd.read_sql(query, engine, params={'limit': limit})
        return df
    except Exception as e:
        st.warning(f"ç„¡æ³•è®€å–æ­·å²è¨˜éŒ„ï¼š{str(e)}")
        return None

# å‡½æ•¸ï¼šç”Ÿæˆ PDF å ±å‘Š
def generate_pdf_report(model_results, correlations, dataset_info):
    """ç”Ÿæˆ PDF å ±å‘Š"""
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    story = []
    styles = getSampleStyleSheet()
    
    # æ¨™é¡Œ
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=24,
        textColor=colors.HexColor('#1f77b4'),
        spaceAfter=30,
        alignment=1
    )
    story.append(Paragraph("Stock Market Prediction Report", title_style))
    story.append(Spacer(1, 0.3*inch))
    
    # å ±å‘Šç”Ÿæˆæ™‚é–“
    story.append(Paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal']))
    story.append(Spacer(1, 0.2*inch))
    
    # æ•¸æ“šé›†è³‡è¨Š
    story.append(Paragraph("Dataset Information", styles['Heading2']))
    data_table = [
        ['Item', 'Value'],
        ['Dataset Name', dataset_info.get('name', 'N/A')],
        ['Total Rows', str(dataset_info.get('rows', 'N/A'))],
        ['Features Used', str(dataset_info.get('features', 'N/A'))]
    ]
    t = Table(data_table, colWidths=[2*inch, 3*inch])
    t.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 12),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    story.append(t)
    story.append(Spacer(1, 0.3*inch))
    
    # æ¨¡å‹æ•ˆèƒ½æ¯”è¼ƒ
    if model_results:
        story.append(Paragraph("Model Performance Comparison", styles['Heading2']))
        perf_data = [['Model', 'MAE', 'RMSE', 'RÂ² Score']]
        for model_name, results in model_results.items():
            perf_data.append([
                model_name,
                f"{results.get('mae', 0):.4f}",
                f"{results.get('rmse', 0):.4f}",
                f"{results.get('r2', 0):.4f}"
            ])
        
        t = Table(perf_data, colWidths=[2*inch, 1.5*inch, 1.5*inch, 1.5*inch])
        t.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 11),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.lightblue),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(t)
        story.append(Spacer(1, 0.3*inch))
    
    # ç›¸é—œæ€§åˆ†æ
    if correlations:
        story.append(Paragraph("Correlation Analysis", styles['Heading2']))
        corr_data = [['Feature', 'Correlation']]
        for feature, corr in sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)[:10]:
            corr_data.append([feature, f"{corr:.4f}"])
        
        t = Table(corr_data, colWidths=[3*inch, 2*inch])
        t.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 11),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.lightgreen),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(t)
    
    doc.build(story)
    buffer.seek(0)
    return buffer

# ä¸»è¦æ‡‰ç”¨ç¨‹å¼é‚è¼¯
if uploaded_file is not None:
    # è®€å–æ•¸æ“š
    df = load_data(uploaded_file)
    
    if df is not None:
        st.session_state.data = df
        
        # é©—è­‰å·²ä¿å­˜çš„æ¬„ä½æ˜¯å¦ä»ç„¶å­˜åœ¨æ–¼æ–°æ•¸æ“šä¸­
        if st.session_state.manual_override:
            saved_close = st.session_state.close_col
            saved_predictions = st.session_state.prediction_cols
            
            # æª¢æŸ¥ä¿å­˜çš„æ¬„ä½æ˜¯å¦å­˜åœ¨
            close_exists = saved_close and saved_close in df.columns
            predictions_exist = all(col in df.columns for col in saved_predictions) if saved_predictions else False
            
            # å¦‚æœæ¬„ä½ä¸å­˜åœ¨ï¼Œé‡ç½®ç‚ºè‡ªå‹•è­˜åˆ¥
            if not close_exists or not predictions_exist:
                st.warning("âš ï¸ æª¢æ¸¬åˆ°æ–°æ•¸æ“šï¼Œå·²é‡ç½®æ¬„ä½è¨­å®šã€‚è«‹é‡æ–°é¸æ“‡æ¬„ä½ã€‚")
                st.session_state.manual_override = False
        
        # æ™ºæ…§è­˜åˆ¥é æ¸¬æ¬„ä½ï¼ˆåƒ…åœ¨æœªæ‰‹å‹•è¨­å®šæ™‚ï¼‰
        if not st.session_state.manual_override:
            prediction_cols = identify_columns(df)
            st.session_state.prediction_cols = prediction_cols
            
            # æ‰¾å‡ºæ”¶ç›¤åƒ¹æ¬„ä½ï¼ˆåœ¨ä½¿ç”¨å‰å…ˆå®šç¾©ï¼‰
            close_col = None
            for col in df.columns:
                if 'æ”¶ç›¤åƒ¹' in str(col) or 'close' in str(col).lower():
                    close_col = col
                    break
            st.session_state.close_col = close_col
        else:
            # ä½¿ç”¨å·²å„²å­˜çš„æ‰‹å‹•è¨­å®š
            prediction_cols = st.session_state.prediction_cols
            close_col = st.session_state.close_col
        
        # é¡¯ç¤ºæ•¸æ“šæ¦‚è¦½
        st.header("ğŸ“Š æ•¸æ“šæ¦‚è¦½")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç¸½è³‡æ–™ç­†æ•¸", len(df))
        with col2:
            st.metric("ç¸½æ¬„ä½æ•¸", len(df.columns))
        with col3:
            st.metric("é æ¸¬æ¬„ä½æ•¸", len(prediction_cols))
        with col4:
            missing_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100)
            st.metric("ç¼ºå¤±å€¼æ¯”ä¾‹", f"{missing_pct:.2f}%")
        
        # é¡¯ç¤ºå‰å¹¾ç­†è³‡æ–™
        st.subheader("ğŸ“‹ æ•¸æ“šé è¦½")
        st.dataframe(df.head(10), width='stretch')
        
        # é¡¯ç¤ºè­˜åˆ¥åˆ°çš„é æ¸¬æ¬„ä½
        if prediction_cols:
            st.success(f"âœ… æˆåŠŸè­˜åˆ¥ {len(prediction_cols)} å€‹é æ¸¬æ¬„ä½ï¼š{', '.join(prediction_cols)}")
        else:
            st.warning("âš ï¸ æœªè‡ªå‹•è­˜åˆ¥åˆ°é æ¸¬æ¬„ä½ï¼Œè«‹æ‰‹å‹•é¸æ“‡")
            
        # æ‰‹å‹•æ¬„ä½é¸æ“‡é¸é …
        with st.expander("ğŸ”§ æ‰‹å‹•èª¿æ•´æ¬„ä½è¨­å®š"):
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if len(numeric_cols) == 0:
                st.error("âŒ ç„¡å¯ç”¨çš„æ•¸å€¼æ¬„ä½")
            else:
                # ä½¿ç”¨ session_state ä¸­çš„å€¼ä½œç‚ºé è¨­
                default_close_idx = 0
                if close_col and close_col in numeric_cols:
                    default_close_idx = numeric_cols.index(close_col)
                
                manual_close = st.selectbox(
                    "é¸æ“‡æ”¶ç›¤åƒ¹æ¬„ä½",
                    options=numeric_cols,
                    index=default_close_idx
                )
                
                manual_predictions = st.multiselect(
                    "é¸æ“‡é æ¸¬æ¬„ä½",
                    options=[col for col in numeric_cols if col != manual_close],
                    default=prediction_cols if prediction_cols else []
                )
                
                if st.button("å¥—ç”¨æ‰‹å‹•è¨­å®š"):
                    st.session_state.prediction_cols = manual_predictions
                    st.session_state.close_col = manual_close
                    st.session_state.manual_override = True
                    st.success("âœ… å·²å¥—ç”¨æ‰‹å‹•è¨­å®š")
                    st.rerun()
        
        # çµ±è¨ˆæè¿°
        st.subheader("ğŸ“ˆ çµ±è¨ˆæè¿°")
        st.dataframe(df.describe(), width='stretch')
        
        # ç¼ºå¤±å€¼åˆ†æ
        st.subheader("ğŸ” ç¼ºå¤±å€¼åˆ†æ")
        missing_data = df.isnull().sum()
        missing_data = missing_data[missing_data > 0].sort_values(ascending=False)
        
        if len(missing_data) > 0:
            fig = px.bar(
                x=missing_data.index,
                y=missing_data.values,
                labels={'x': 'Column', 'y': 'Missing Count'},
                title='Missing Values by Column'
            )
            st.plotly_chart(fig, width='stretch')
        else:
            st.success("âœ… æ•¸æ“šå®Œæ•´ï¼Œç„¡ç¼ºå¤±å€¼")
        
        st.markdown("---")
        
        # ç›¸é—œæ€§åˆ†æ
        st.header("ğŸ”— ç›¸é—œæ€§åˆ†æ")
        
        # é©—è­‰æ¬„ä½å­˜åœ¨æ€§
        close_col_valid = close_col and close_col in df.columns
        predictions_valid = prediction_cols and all(col in df.columns for col in prediction_cols)
        
        if close_col_valid and predictions_valid:
            st.subheader(f"é æ¸¬å€¼èˆ‡ {close_col} çš„ç›¸é—œæ€§")
            
            # è¨ˆç®—ç›¸é—œæ€§
            correlations, p_values = calculate_correlations(df, close_col, prediction_cols)
            
            if correlations:
                # å‰µå»ºç›¸é—œæ€§æ•¸æ“šæ¡†
                corr_df = pd.DataFrame({
                    'Feature': list(correlations.keys()),
                    'Correlation': list(correlations.values()),
                    'P-value': [p_values[k] for k in correlations.keys()]
                })
                corr_df = corr_df.sort_values('Correlation', ascending=False, key=abs)
                
                # é¡¯ç¤ºç›¸é—œæ€§è¡¨æ ¼
                st.dataframe(corr_df.style.background_gradient(cmap='RdYlGn', subset=['Correlation']), 
                           width='stretch')
                
                # ç›¸é—œæ€§æ¢å½¢åœ–
                fig = px.bar(
                    corr_df,
                    x='Feature',
                    y='Correlation',
                    color='Correlation',
                    color_continuous_scale='RdYlGn',
                    title='Correlation with Close Price',
                    labels={'Correlation': 'Pearson Correlation Coefficient'}
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig, width='stretch')
                
                # ç›¸é—œæ€§ç†±åŠ›åœ–
                st.subheader("ğŸ“Š ç›¸é—œæ€§ç†±åŠ›åœ–")
                
                # é¸æ“‡åŒ…å«æ”¶ç›¤åƒ¹å’Œé æ¸¬æ¬„ä½çš„å­é›†
                heatmap_cols = [close_col] + prediction_cols
                corr_matrix = df[heatmap_cols].corr()
                
                # ä½¿ç”¨ Plotly å‰µå»ºç†±åŠ›åœ–
                fig = go.Figure(data=go.Heatmap(
                    z=corr_matrix.values,
                    x=corr_matrix.columns,
                    y=corr_matrix.columns,
                    colorscale='RdYlGn',
                    zmid=0,
                    text=corr_matrix.values,
                    texttemplate='%{text:.2f}',
                    textfont={"size": 10},
                    colorbar=dict(title="Correlation")
                ))
                fig.update_layout(
                    title='Correlation Heatmap',
                    xaxis_tickangle=-45,
                    height=600
                )
                st.plotly_chart(fig, width='stretch')
        else:
            if not close_col_valid:
                st.error("âŒ æœªæ‰¾åˆ°æ”¶ç›¤åƒ¹æ¬„ä½ï¼Œè«‹ä½¿ç”¨æ‰‹å‹•èª¿æ•´æ¬„ä½è¨­å®š")
            if not predictions_valid:
                st.error("âŒ æœªæ‰¾åˆ°é æ¸¬æ¬„ä½ï¼Œè«‹ä½¿ç”¨æ‰‹å‹•èª¿æ•´æ¬„ä½è¨­å®š")
        
        st.markdown("---")
        
        # æ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´
        st.header("ğŸ¤– æ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´")
        
        # ä½¿ç”¨ä¹‹å‰é©—è­‰éçš„æ¬„ä½
        if close_col_valid and predictions_valid:
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ç‰¹å¾µé¸æ“‡")
                # è®“ç”¨æˆ¶é¸æ“‡è¦ä½¿ç”¨çš„é æ¸¬æ¬„ä½
                selected_features = st.multiselect(
                    "é¸æ“‡ç”¨æ–¼è¨“ç·´çš„ç‰¹å¾µæ¬„ä½",
                    options=prediction_cols,
                    default=prediction_cols,
                    help="é¸æ“‡æ‚¨æƒ³ç”¨ä¾†é æ¸¬æ”¶ç›¤åƒ¹çš„ç‰¹å¾µ"
                )
                
                # å…¶ä»–æ•¸å€¼æ¬„ä½ä¹Ÿå¯ä»¥ä½œç‚ºç‰¹å¾µ
                numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
                other_features = [col for col in numeric_cols if col not in prediction_cols and col != close_col]
                
                if other_features:
                    additional_features = st.multiselect(
                        "é¸æ“‡å…¶ä»–æ•¸å€¼ç‰¹å¾µï¼ˆå¯é¸ï¼‰",
                        options=other_features,
                        help="ä¾‹å¦‚ï¼šé–‹ç›¤åƒ¹ã€æœ€é«˜åƒ¹ã€æœ€ä½åƒ¹ã€æˆäº¤é‡ç­‰"
                    )
                    selected_features.extend(additional_features)
            
            with col2:
                st.subheader("æ¨¡å‹é¸æ“‡")
                
                # æ ¹æ“š LightGBM å¯ç”¨æ€§èª¿æ•´æ¨¡å‹é¸é …
                model_options = [
                    "Linear Regression",
                    "Random Forest",
                    "XGBoost",
                    "Support Vector Regression (SVR)",
                    "Multi-layer Perceptron (MLP)",
                    "LSTM Neural Network"
                ]
                
                if LIGHTGBM_AVAILABLE:
                    model_options.insert(3, "LightGBM")
                
                model_type = st.selectbox(
                    "é¸æ“‡æ©Ÿå™¨å­¸ç¿’æ¨¡å‹",
                    options=model_options,
                    help="è¨“ç·´çµæœå°‡è‡ªå‹•ä¿å­˜ï¼Œå¯åœ¨ã€Œæ¨¡å‹æ¯”è¼ƒã€é é¢æŸ¥çœ‹æ‰€æœ‰å·²è¨“ç·´æ¨¡å‹çš„æ¯”è¼ƒ"
                )
                
                test_size = st.slider(
                    "æ¸¬è©¦é›†æ¯”ä¾‹",
                    min_value=0.1,
                    max_value=0.4,
                    value=0.2,
                    step=0.05,
                    help="ç”¨æ–¼æ¸¬è©¦çš„æ•¸æ“šæ¯”ä¾‹"
                )
            
            # è¶…åƒæ•¸èª¿æ•´
            st.markdown("---")
            st.subheader("âš™ï¸ æ¨¡å‹åƒæ•¸èª¿æ•´")
            
            show_params = st.checkbox("é¡¯ç¤ºé€²éšåƒæ•¸è¨­å®š", value=False)
            
            model_params = {}
            if show_params:
                if model_type == "Random Forest":
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        n_estimators = st.slider("æ¨¹çš„æ•¸é‡ (n_estimators)", 50, 500, 100, 50)
                    with col2:
                        max_depth = st.slider("æœ€å¤§æ·±åº¦ (max_depth)", 3, 30, 10, 1)
                    with col3:
                        min_samples_split = st.slider("æœ€å°åˆ†å‰²æ¨£æœ¬æ•¸", 2, 20, 2, 1)
                    model_params = {'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_split': min_samples_split}
                
                elif model_type == "XGBoost":
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        n_estimators = st.slider("æ¨¹çš„æ•¸é‡", 50, 500, 100, 50)
                    with col2:
                        learning_rate = st.slider("å­¸ç¿’ç‡", 0.01, 0.3, 0.1, 0.01)
                    with col3:
                        max_depth = st.slider("æœ€å¤§æ·±åº¦", 3, 15, 6, 1)
                    model_params = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'max_depth': max_depth}
                
                elif model_type == "LightGBM":
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        n_estimators = st.slider("æ¨¹çš„æ•¸é‡", 50, 500, 100, 50)
                    with col2:
                        learning_rate = st.slider("å­¸ç¿’ç‡", 0.01, 0.3, 0.1, 0.01)
                    with col3:
                        num_leaves = st.slider("è‘‰å­æ•¸é‡", 20, 200, 31, 5)
                    model_params = {'n_estimators': n_estimators, 'learning_rate': learning_rate, 'num_leaves': num_leaves}
                
                elif model_type == "Support Vector Regression (SVR)":
                    col1, col2 = st.columns(2)
                    with col1:
                        C = st.slider("æ‡²ç½°åƒæ•¸ C", 0.1, 10.0, 1.0, 0.1)
                    with col2:
                        kernel = st.selectbox("æ ¸å‡½æ•¸", ['rbf', 'linear', 'poly'])
                    model_params = {'C': C, 'kernel': kernel}
                
                elif model_type == "Multi-layer Perceptron (MLP)":
                    col1, col2 = st.columns(2)
                    with col1:
                        hidden_layers = st.text_input("éš±è—å±¤çµæ§‹ (é€—è™Ÿåˆ†éš”)", "100,50")
                        try:
                            hidden_layer_sizes = tuple(map(int, hidden_layers.split(',')))
                        except:
                            hidden_layer_sizes = (100, 50)
                    with col2:
                        max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•¸", 100, 1000, 500, 50)
                    model_params = {'hidden_layer_sizes': hidden_layer_sizes, 'max_iter': max_iter}
                
                elif model_type == "LSTM Neural Network":
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        lstm_units = st.slider("LSTM å–®å…ƒæ•¸", 32, 256, 50, 16)
                    with col2:
                        epochs = st.slider("è¨“ç·´é€±æœŸ", 10, 100, 50, 10)
                    with col3:
                        batch_size = st.slider("æ‰¹æ¬¡å¤§å°", 8, 64, 32, 8)
                    model_params = {'lstm_units': lstm_units, 'epochs': epochs, 'batch_size': batch_size}
            else:
                # ä½¿ç”¨é è¨­åƒæ•¸
                if model_type == "Random Forest":
                    model_params = {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2}
                elif model_type == "XGBoost":
                    model_params = {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 6}
                elif model_type == "LightGBM":
                    model_params = {'n_estimators': 100, 'learning_rate': 0.1, 'num_leaves': 31}
                elif model_type == "Support Vector Regression (SVR)":
                    model_params = {'C': 1.0, 'kernel': 'rbf'}
                elif model_type == "Multi-layer Perceptron (MLP)":
                    model_params = {'hidden_layer_sizes': (100, 50), 'max_iter': 500}
                elif model_type == "LSTM Neural Network":
                    model_params = {'lstm_units': 50, 'epochs': 50, 'batch_size': 32}
            
            if selected_features and st.button("ğŸš€ è¨“ç·´æ¨¡å‹", type="primary"):
                with st.spinner("æ­£åœ¨è¨“ç·´æ¨¡å‹ï¼Œè«‹ç¨å€™..."):
                    try:
                        # æº–å‚™æ•¸æ“š
                        df_clean = df[selected_features + [close_col]].dropna()
                        
                        if len(df_clean) < 10:
                            st.error("âŒ æ•¸æ“šé‡ä¸è¶³ï¼Œè«‹ç¢ºä¿è‡³å°‘æœ‰ 10 ç­†å®Œæ•´æ•¸æ“š")
                        else:
                            X = df_clean[selected_features]
                            y = df_clean[close_col]
                            
                            # å°æ–¼ LSTM ä½¿ç”¨æ™‚åºåˆ†å‰²ï¼Œå…¶ä»–æ¨¡å‹ä½¿ç”¨éš¨æ©Ÿåˆ†å‰²
                            if model_type == "LSTM Neural Network":
                                # æ™‚åºåˆ†å‰²ï¼ˆä¸æ‰“äº‚é †åºï¼‰
                                split_idx = int(len(X) * (1 - test_size))
                                X_train = X.iloc[:split_idx].copy()
                                X_test = X.iloc[split_idx:].copy()
                                y_train = y.iloc[:split_idx].copy()
                                y_test = y.iloc[split_idx:].copy()
                            else:
                                # éš¨æ©Ÿåˆ†å‰²
                                X_train, X_test, y_train, y_test = train_test_split(
                                    X, y, test_size=test_size, random_state=42, shuffle=True
                                )
                            
                            # æ¨™æº–åŒ–
                            scaler = StandardScaler()
                            X_train_scaled = scaler.fit_transform(X_train)
                            X_test_scaled = scaler.transform(X_test)
                            
                            # åˆå§‹åŒ–è®Šé‡
                            model = None
                            y_pred_train = None
                            y_pred_test = None
                            
                            # è¨“ç·´æ¨¡å‹ï¼ˆä½¿ç”¨è‡ªè¨‚åƒæ•¸ï¼‰
                            if model_type == "Linear Regression":
                                model = LinearRegression()
                                model.fit(X_train_scaled, y_train)
                                y_pred_train = model.predict(X_train_scaled)
                                y_pred_test = model.predict(X_test_scaled)
                            
                            elif model_type == "Random Forest":
                                model = RandomForestRegressor(
                                    n_estimators=model_params.get('n_estimators', 100),
                                    max_depth=model_params.get('max_depth', None),
                                    min_samples_split=model_params.get('min_samples_split', 2),
                                    random_state=42,
                                    n_jobs=-1
                                )
                                model.fit(X_train_scaled, y_train)
                                y_pred_train = model.predict(X_train_scaled)
                                y_pred_test = model.predict(X_test_scaled)
                            
                            elif model_type == "XGBoost":
                                model = xgb.XGBRegressor(
                                    n_estimators=model_params.get('n_estimators', 100),
                                    learning_rate=model_params.get('learning_rate', 0.1),
                                    max_depth=model_params.get('max_depth', 6),
                                    random_state=42,
                                    n_jobs=-1
                                )
                                model.fit(X_train_scaled, y_train)
                                y_pred_train = model.predict(X_train_scaled)
                                y_pred_test = model.predict(X_test_scaled)
                            
                            elif model_type == "LightGBM":
                                if LIGHTGBM_AVAILABLE and lgb is not None:
                                    model = lgb.LGBMRegressor(
                                        n_estimators=model_params.get('n_estimators', 100),
                                        learning_rate=model_params.get('learning_rate', 0.1),
                                        num_leaves=model_params.get('num_leaves', 31),
                                        random_state=42,
                                        n_jobs=-1,
                                        verbose=-1
                                    )
                                    model.fit(X_train_scaled, y_train)
                                    y_pred_train = model.predict(X_train_scaled)
                                    y_pred_test = model.predict(X_test_scaled)
                                else:
                                    st.error("âŒ LightGBM ä¸å¯ç”¨ï¼Œè«‹é¸æ“‡å…¶ä»–æ¨¡å‹")
                            
                            elif model_type == "Support Vector Regression (SVR)":
                                kernel_value = model_params.get('kernel', 'rbf')
                                if isinstance(kernel_value, int):
                                    kernel_value = 'rbf'
                                model = SVR(
                                    kernel=str(kernel_value),
                                    C=model_params.get('C', 1.0)
                                )
                                model.fit(X_train_scaled, y_train)
                                y_pred_train = model.predict(X_train_scaled)
                                y_pred_test = model.predict(X_test_scaled)
                            
                            elif model_type == "Multi-layer Perceptron (MLP)":
                                model = MLPRegressor(
                                    hidden_layer_sizes=model_params.get('hidden_layer_sizes', (100, 50)),
                                    max_iter=model_params.get('max_iter', 500),
                                    random_state=42
                                )
                                model.fit(X_train_scaled, y_train)
                                y_pred_train = model.predict(X_train_scaled)
                                y_pred_test = model.predict(X_test_scaled)
                            
                            elif model_type == "LSTM Neural Network":
                                # è¨­å®šæ™‚åºçª—å£å¤§å°ï¼ˆç¢ºä¿è¨“ç·´é›†å’Œæ¸¬è©¦é›†éƒ½èƒ½ç”¢ç”Ÿåºåˆ—ï¼‰
                                max_time_steps = min(5, len(X_train_scaled) - 1, len(X_test_scaled) - 1)
                                time_steps = max(1, max_time_steps)  # è‡³å°‘ç‚º 1
                                
                                # å‰µå»ºæ™‚åºçª—å£æ•¸æ“š
                                y_train_array = np.array(y_train) if isinstance(y_train, pd.Series) else y_train
                                y_test_array = np.array(y_test) if isinstance(y_test, pd.Series) else y_test
                                X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_array, time_steps)
                                X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_array, time_steps)
                                
                                # æª¢æŸ¥åºåˆ—æ˜¯å¦ç‚ºç©º
                                if len(X_train_seq) < 10 or len(X_test_seq) < 1:
                                    st.warning(f"âš ï¸ LSTM éœ€è¦è¼ƒå¤šæ•¸æ“šã€‚ç•¶å‰æ™‚åºçª—å£ {time_steps} æ­¥å¾Œåƒ…å‰© {len(X_train_seq)} ç­†è¨“ç·´æ•¸æ“šã€‚ä½¿ç”¨ MLP æ¨¡å‹ä»£æ›¿ã€‚")
                                    model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
                                    model.fit(X_train_scaled, y_train)
                                    y_pred_train = model.predict(X_train_scaled)
                                    y_pred_test = model.predict(X_test_scaled)
                                else:
                                    # å»ºç«‹ LSTM æ¨¡å‹ï¼ˆä½¿ç”¨è‡ªè¨‚åƒæ•¸ï¼‰
                                    lstm_units = model_params.get('lstm_units', 50)
                                    epochs = model_params.get('epochs', 50)
                                    batch_size = model_params.get('batch_size', 32)
                                    
                                    model = keras.Sequential([
                                        layers.LSTM(lstm_units, activation='relu', input_shape=(time_steps, X_train_scaled.shape[1])),
                                        layers.Dropout(0.2),
                                        layers.Dense(lstm_units // 2, activation='relu'),
                                        layers.Dense(1)
                                    ])
                                    model.compile(optimizer='adam', loss='mse')
                                    model.fit(X_train_seq, y_train_seq, epochs=epochs, batch_size=batch_size, verbose=0, validation_split=0.1)
                                    
                                    # é æ¸¬ï¼ˆéœ€è¦å°å®Œæ•´æ•¸æ“šé›†é€²è¡Œé æ¸¬ä»¥åŒ¹é…åŸå§‹ y çš„é•·åº¦ï¼‰
                                    y_pred_train_seq = model.predict(X_train_seq, verbose=0).flatten()
                                    y_pred_test_seq = model.predict(X_test_seq, verbose=0).flatten()
                                    
                                    # èª¿æ•´ y ä»¥åŒ¹é…åºåˆ—é•·åº¦
                                    y_train = pd.Series(y_train_seq)
                                    y_test = pd.Series(y_test_seq)
                                    y_pred_train = y_pred_train_seq
                                    y_pred_test = y_pred_test_seq
                            
                            # æª¢æŸ¥é æ¸¬æ˜¯å¦æˆåŠŸ
                            if y_pred_train is None or y_pred_test is None or model is None:
                                if model is None:
                                    st.error("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—")
                                else:
                                    st.error("âŒ æ¨¡å‹è¨“ç·´å¤±æ•—")
                            else:
                                # è¨ˆç®—è©•ä¼°æŒ‡æ¨™
                                train_mae = mean_absolute_error(y_train, y_pred_train)
                                train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
                                train_r2 = r2_score(y_train, y_pred_train)
                                
                                test_mae = mean_absolute_error(y_test, y_pred_test)
                                test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
                                test_r2 = r2_score(y_test, y_pred_test)
                                
                                # é¡¯ç¤ºçµæœ
                                st.success("âœ… æ¨¡å‹è¨“ç·´å®Œæˆï¼")
                            
                                st.subheader("ğŸ“Š æ¨¡å‹æ•ˆèƒ½è©•ä¼°")
                                
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.markdown("**è¨“ç·´é›†è¡¨ç¾**")
                                    metrics_train = pd.DataFrame({
                                        'Metric': ['MAE', 'RMSE', 'RÂ² Score'],
                                        'Value': [train_mae, train_rmse, train_r2]
                                    })
                                    st.dataframe(metrics_train, width='stretch', hide_index=True)
                                
                                with col2:
                                    st.markdown("**æ¸¬è©¦é›†è¡¨ç¾**")
                                    metrics_test = pd.DataFrame({
                                        'Metric': ['MAE', 'RMSE', 'RÂ² Score'],
                                        'Value': [test_mae, test_rmse, test_r2]
                                    })
                                    st.dataframe(metrics_test, width='stretch', hide_index=True)
                                
                                # é æ¸¬ vs å¯¦éš›å€¼åœ–è¡¨
                                st.subheader("ğŸ“ˆ é æ¸¬çµæœè¦–è¦ºåŒ–")
                                
                                # å‰µå»ºå­åœ–
                                fig = make_subplots(
                                    rows=1, cols=2,
                                    subplot_titles=('Training Set', 'Test Set')
                                )
                                
                                # ç¢ºä¿ y_train å’Œ y_test æ˜¯æ•¸çµ„æˆ– Series
                                y_train_array = np.array(y_train) if not isinstance(y_train, np.ndarray) else y_train
                                y_test_array = np.array(y_test) if not isinstance(y_test, np.ndarray) else y_test
                                y_pred_train_array = np.array(y_pred_train) if not isinstance(y_pred_train, np.ndarray) else y_pred_train
                                y_pred_test_array = np.array(y_pred_test) if not isinstance(y_pred_test, np.ndarray) else y_pred_test
                            
                                # è¨“ç·´é›†
                                fig.add_trace(
                                    go.Scatter(x=y_train_array, y=y_pred_train_array, mode='markers',
                                             name='Train', marker=dict(color='blue', opacity=0.5)),
                                    row=1, col=1
                                )
                                fig.add_trace(
                                    go.Scatter(x=[float(np.min(y_train_array)), float(np.max(y_train_array))],
                                             y=[float(np.min(y_train_array)), float(np.max(y_train_array))],
                                             mode='lines', name='Perfect Prediction',
                                             line=dict(color='red', dash='dash')),
                                    row=1, col=1
                                )
                                
                                # æ¸¬è©¦é›†
                                fig.add_trace(
                                    go.Scatter(x=y_test_array, y=y_pred_test_array, mode='markers',
                                             name='Test', marker=dict(color='green', opacity=0.5)),
                                    row=1, col=2
                                )
                                fig.add_trace(
                                    go.Scatter(x=[float(np.min(y_test_array)), float(np.max(y_test_array))],
                                             y=[float(np.min(y_test_array)), float(np.max(y_test_array))],
                                             mode='lines', name='Perfect Prediction',
                                             line=dict(color='red', dash='dash')),
                                    row=1, col=2
                                )
                                
                                fig.update_xaxes(title_text="Actual Close Price", row=1, col=1)
                                fig.update_xaxes(title_text="Actual Close Price", row=1, col=2)
                                fig.update_yaxes(title_text="Predicted Close Price", row=1, col=1)
                                fig.update_yaxes(title_text="Predicted Close Price", row=1, col=2)
                                
                                fig.update_layout(height=500, showlegend=True)
                                st.plotly_chart(fig, width='stretch')
                            
                                # ç‰¹å¾µé‡è¦æ€§ï¼ˆé©ç”¨æ–¼æ¨¹æ¨¡å‹ï¼‰
                                if model_type in ["Random Forest", "XGBoost", "LightGBM"]:
                                    st.subheader("ğŸ¯ ç‰¹å¾µé‡è¦æ€§åˆ†æ")
                                    
                                    if hasattr(model, 'feature_importances_'):
                                        importance_df = pd.DataFrame({
                                            'Feature': selected_features,
                                            'Importance': model.feature_importances_
                                        }).sort_values('Importance', ascending=False)
                                        
                                        fig = px.bar(
                                            importance_df,
                                            x='Importance',
                                            y='Feature',
                                            orientation='h',
                                            title='Feature Importance',
                                            labels={'Importance': 'Importance Score'}
                                        )
                                        fig.update_layout(yaxis={'categoryorder': 'total ascending'})
                                        st.plotly_chart(fig, width='stretch')
                                
                                # å„²å­˜æ¨¡å‹åˆ° session state
                                st.session_state.model_trained = True
                                st.session_state.model = model
                                st.session_state.scaler = scaler
                                st.session_state.selected_features = selected_features
                                st.session_state.model_type = model_type
                                
                                # æº–å‚™æ•¸æ“šä¿å­˜åˆ°è³‡æ–™åº«
                                feature_importance_dict = None
                                if model_type in ["Random Forest", "XGBoost", "LightGBM"] and hasattr(model, 'feature_importances_'):
                                    feature_importance_dict = {
                                        feat: float(imp) for feat, imp in zip(selected_features, model.feature_importances_)
                                    }
                                
                                predictions_list = y_pred_test_array.tolist() if hasattr(y_pred_test_array, 'tolist') else list(y_pred_test_array)
                                
                                # ä¿å­˜åˆ°è³‡æ–™åº«
                                save_result = save_prediction_to_db(
                                    model_type=model_type,
                                    model_params={'test_size': test_size},
                                    features_used=selected_features,
                                    test_size=test_size,
                                    mae=test_mae,
                                    rmse=test_rmse,
                                    r2=test_r2,
                                    dataset_name=uploaded_file.name if uploaded_file else 'Unknown',
                                    dataset_rows=len(df_clean),
                                    predictions=predictions_list[:100],  # åªä¿å­˜å‰100å€‹é æ¸¬
                                    feature_importance=feature_importance_dict
                                )
                                
                                if save_result:
                                    st.success("âœ… é æ¸¬è¨˜éŒ„å·²ä¿å­˜åˆ°æ­·å²è³‡æ–™åº«")
                                
                                # ä¹Ÿä¿å­˜åˆ° model_results ç”¨æ–¼æ¯”è¼ƒ
                                st.session_state.model_results[model_type] = {
                                    'mae': test_mae,
                                    'rmse': test_rmse,
                                    'r2': test_r2,
                                    'predictions': y_pred_test,
                                    'y_test': y_test,
                                    'feature_importance': feature_importance_dict
                                }
                            
                    except Exception as e:
                        st.error(f"âŒ è¨“ç·´æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                        import traceback
                        st.code(traceback.format_exc())
        
        else:
            if not close_col_valid:
                st.error("âŒ æœªæ‰¾åˆ°æ”¶ç›¤åƒ¹æ¬„ä½ï¼Œè«‹ä½¿ç”¨æ‰‹å‹•èª¿æ•´æ¬„ä½è¨­å®š")
            if not predictions_valid:
                st.error("âŒ æœªæ‰¾åˆ°é æ¸¬æ¬„ä½ï¼Œè«‹ä½¿ç”¨æ‰‹å‹•èª¿æ•´æ¬„ä½è¨­å®š")
        
        # === æ–°å¢åŠŸèƒ½å€æ®µ ===
        if page == "æ¨¡å‹æ¯”è¼ƒ" and st.session_state.model_results:
            st.markdown("---")
            st.header("ğŸ“Š æ¨¡å‹æ•ˆèƒ½æ¯”è¼ƒ")
            
            # é¡¯ç¤ºæ‰€æœ‰å·²è¨“ç·´æ¨¡å‹çš„æ¯”è¼ƒ
            if len(st.session_state.model_results) > 0:
                st.subheader("æ•ˆèƒ½æŒ‡æ¨™æ¯”è¼ƒ")
                
                # å‰µå»ºæ¯”è¼ƒè¡¨æ ¼
                comparison_data = []
                for model_name, results in st.session_state.model_results.items():
                    comparison_data.append({
                        'Model': model_name,
                        'MAE': results['mae'],
                        'RMSE': results['rmse'],
                        'RÂ² Score': results['r2']
                    })
                
                comparison_df = pd.DataFrame(comparison_data)
                st.dataframe(comparison_df.style.highlight_max(axis=0, subset=['RÂ² Score'], color='lightgreen')
                            .highlight_min(axis=0, subset=['MAE', 'RMSE'], color='lightgreen'))
                
                # è¦–è¦ºåŒ–æ¯”è¼ƒ
                col1, col2 = st.columns(2)
                
                with col1:
                    fig = go.Figure()
                    for metric in ['MAE', 'RMSE']:
                        fig.add_trace(go.Bar(
                            name=metric,
                            x=comparison_df['Model'],
                            y=comparison_df[metric],
                        ))
                    fig.update_layout(
                        title='Error Metrics Comparison',
                        barmode='group',
                        xaxis_title='Model',
                        yaxis_title='Error Value'
                    )
                    st.plotly_chart(fig, width='stretch')
                
                with col2:
                    fig = px.bar(
                        comparison_df,
                        x='Model',
                        y='RÂ² Score',
                        title='RÂ² Score Comparison',
                        labels={'RÂ² Score': 'RÂ² Score'}
                    )
                    st.plotly_chart(fig, width='stretch')
            else:
                st.info("è«‹å…ˆè¨“ç·´è‡³å°‘ä¸€å€‹æ¨¡å‹")
        
        elif page == "æ­·å²è¨˜éŒ„":
            st.markdown("---")
            st.header("ğŸ“œ æ­·å²é æ¸¬è¨˜éŒ„")
            
            if engine:
                history_df = get_prediction_history(limit=20)
                
                if history_df is not None and len(history_df) > 0:
                    st.subheader(f"æœ€è¿‘ {len(history_df)} ç­†è¨˜éŒ„")
                    
                    # é¡¯ç¤ºæ­·å²è¨˜éŒ„
                    display_cols = ['created_at', 'model_type', 'mae', 'rmse', 'r2_score', 'dataset_name', 'dataset_rows']
                    display_df = history_df[display_cols].copy()
                    display_df.columns = ['æ™‚é–“', 'æ¨¡å‹é¡å‹', 'MAE', 'RMSE', 'RÂ² Score', 'æ•¸æ“šé›†', 'æ•¸æ“šé‡']
                    st.dataframe(display_df, width='stretch')
                    
                    # æ•ˆèƒ½è¶¨å‹¢åœ–
                    st.subheader("ğŸ“ˆ æ•ˆèƒ½è¶¨å‹¢åˆ†æ")
                    
                    fig = make_subplots(
                        rows=1, cols=2,
                        subplot_titles=('MAE Trend', 'RÂ² Score Trend')
                    )
                    
                    fig.add_trace(
                        go.Scatter(x=history_df['created_at'], y=history_df['mae'], 
                                 mode='lines+markers', name='MAE'),
                        row=1, col=1
                    )
                    
                    fig.add_trace(
                        go.Scatter(x=history_df['created_at'], y=history_df['r2_score'], 
                                 mode='lines+markers', name='RÂ² Score'),
                        row=1, col=2
                    )
                    
                    fig.update_xaxes(title_text="Time", row=1, col=1)
                    fig.update_xaxes(title_text="Time", row=1, col=2)
                    fig.update_yaxes(title_text="MAE", row=1, col=1)
                    fig.update_yaxes(title_text="RÂ² Score", row=1, col=2)
                    
                    st.plotly_chart(fig, width='stretch')
                else:
                    st.info("æš«ç„¡æ­·å²è¨˜éŒ„")
            else:
                st.warning("è³‡æ–™åº«æœªé€£æ¥")
        
        elif page == "ç‰¹å¾µå·¥ç¨‹":
            st.markdown("---")
            st.header("âš™ï¸ é€²éšç‰¹å¾µå·¥ç¨‹")
            
            if close_col_valid:
                st.subheader("æŠ€è¡“æŒ‡æ¨™è¨ˆç®—")
                
                enable_features = st.checkbox("å•Ÿç”¨æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ", value=False)
                
                if enable_features:
                    with st.spinner("æ­£åœ¨è¨ˆç®—æŠ€è¡“æŒ‡æ¨™..."):
                        # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
                        df_enhanced = calculate_technical_indicators(df, close_col)
                        st.session_state.feature_engineered_data = df_enhanced
                        
                        # é¡¯ç¤ºæ–°å¢çš„ç‰¹å¾µ
                        new_features = [col for col in df_enhanced.columns if col not in df.columns]
                        
                        if new_features:
                            st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(new_features)} å€‹æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ")
                            
                            # é¡¯ç¤ºæ–°ç‰¹å¾µåˆ—è¡¨
                            st.subheader("æ–°å¢ç‰¹å¾µåˆ—è¡¨")
                            col1, col2, col3 = st.columns(3)
                            
                            features_by_category = {
                                'ç§»å‹•å¹³å‡': [f for f in new_features if 'SMA' in f or 'EMA' in f],
                                'æŠ€è¡“æŒ‡æ¨™': [f for f in new_features if any(x in f for x in ['RSI', 'MACD', 'BB'])],
                                'å…¶ä»–æŒ‡æ¨™': [f for f in new_features if f not in [f for f in new_features if 'SMA' in f or 'EMA' in f or any(x in f for x in ['RSI', 'MACD', 'BB'])]]
                            }
                            
                            with col1:
                                st.write("**ç§»å‹•å¹³å‡**")
                                for f in features_by_category['ç§»å‹•å¹³å‡']:
                                    st.write(f"- {f}")
                            
                            with col2:
                                st.write("**æŠ€è¡“æŒ‡æ¨™**")
                                for f in features_by_category['æŠ€è¡“æŒ‡æ¨™']:
                                    st.write(f"- {f}")
                            
                            with col3:
                                st.write("**å…¶ä»–æŒ‡æ¨™**")
                                for f in features_by_category['å…¶ä»–æŒ‡æ¨™']:
                                    st.write(f"- {f}")
                            
                            # é¡¯ç¤ºå¢å¼·å¾Œçš„æ•¸æ“šé è¦½
                            st.subheader("å¢å¼·å¾Œçš„æ•¸æ“šé è¦½")
                            st.dataframe(df_enhanced.tail(10), width='stretch')
                            
                            st.info("ğŸ’¡ æç¤ºï¼šæ‚¨ç¾åœ¨å¯ä»¥åœ¨æ¨¡å‹è¨“ç·´ä¸­ä½¿ç”¨é€™äº›æ–°ç‰¹å¾µ")
                else:
                    st.info("å‹¾é¸ä¸Šæ–¹é¸é …ä»¥å•Ÿç”¨æŠ€è¡“æŒ‡æ¨™è¨ˆç®—")
            else:
                st.error("âŒ éœ€è¦æœ‰æ•ˆçš„æ”¶ç›¤åƒ¹æ¬„ä½æ‰èƒ½è¨ˆç®—æŠ€è¡“æŒ‡æ¨™")
        
        elif page == "åŒ¯å‡ºå ±å‘Š":
            st.markdown("---")
            st.header("ğŸ“¥ åŒ¯å‡ºé æ¸¬å ±å‘Š")
            
            if st.session_state.model_results or (close_col_valid and predictions_valid):
                st.subheader("é¸æ“‡åŒ¯å‡ºæ ¼å¼")
                
                export_format = st.radio(
                    "å ±å‘Šæ ¼å¼",
                    ["CSV", "Excel", "PDF"],
                    horizontal=True
                )
                
                col1, col2 = st.columns(2)
                
                with col1:
                    include_correlations = st.checkbox("åŒ…å«ç›¸é—œæ€§åˆ†æ", value=True)
                
                with col2:
                    include_predictions = st.checkbox("åŒ…å«é æ¸¬çµæœ", value=True)
                
                if st.button("ğŸ¯ ç”Ÿæˆå ±å‘Š", type="primary"):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå ±å‘Š..."):
                        try:
                            if export_format == "CSV":
                                # ç”Ÿæˆ CSV
                                buffer = io.BytesIO()
                                
                                if st.session_state.model_results:
                                    # åŒ¯å‡ºæ¨¡å‹æ¯”è¼ƒçµæœ
                                    comparison_data = []
                                    for model_name, results in st.session_state.model_results.items():
                                        comparison_data.append({
                                            'Model': model_name,
                                            'MAE': results['mae'],
                                            'RMSE': results['rmse'],
                                            'RÂ² Score': results['r2']
                                        })
                                    comparison_df = pd.DataFrame(comparison_data)
                                    csv_data = comparison_df.to_csv(index=False)
                                    buffer.write(csv_data.encode())
                                    buffer.seek(0)
                                    
                                    st.download_button(
                                        label="ğŸ“¥ ä¸‹è¼‰ CSV å ±å‘Š",
                                        data=buffer,
                                        file_name=f"prediction_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                        mime="text/csv"
                                    )
                                    st.success("âœ… CSV å ±å‘Šå·²ç”Ÿæˆ")
                            
                            elif export_format == "Excel":
                                # ç”Ÿæˆ Excel
                                buffer = io.BytesIO()
                                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                    # æ¨¡å‹æ¯”è¼ƒçµæœ
                                    if st.session_state.model_results:
                                        comparison_data = []
                                        for model_name, results in st.session_state.model_results.items():
                                            comparison_data.append({
                                                'Model': model_name,
                                                'MAE': results['mae'],
                                                'RMSE': results['rmse'],
                                                'RÂ² Score': results['r2']
                                            })
                                        comparison_df = pd.DataFrame(comparison_data)
                                        comparison_df.to_excel(writer, sheet_name='Model Comparison', index=False)
                                    
                                    # ç›¸é—œæ€§åˆ†æ
                                    if include_correlations and close_col_valid and predictions_valid:
                                        correlations, p_values = calculate_correlations(df, close_col, prediction_cols)
                                        corr_df = pd.DataFrame({
                                            'Feature': list(correlations.keys()),
                                            'Correlation': list(correlations.values()),
                                            'P-Value': [p_values.get(k, None) for k in correlations.keys()]
                                        })
                                        corr_df.to_excel(writer, sheet_name='Correlations', index=False)
                                    
                                    # æ•¸æ“šçµ±è¨ˆ
                                    df.describe().to_excel(writer, sheet_name='Data Statistics')
                                
                                buffer.seek(0)
                                
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š",
                                    data=buffer,
                                    file_name=f"prediction_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                                st.success("âœ… Excel å ±å‘Šå·²ç”Ÿæˆ")
                            
                            elif export_format == "PDF":
                                # ç”Ÿæˆ PDF
                                correlations_dict = None
                                if include_correlations and close_col_valid and predictions_valid:
                                    correlations_dict, _ = calculate_correlations(df, close_col, prediction_cols)
                                
                                dataset_info = {
                                    'name': uploaded_file.name if uploaded_file else 'Unknown',
                                    'rows': len(df),
                                    'features': len(prediction_cols) if predictions_valid else 0
                                }
                                
                                pdf_buffer = generate_pdf_report(
                                    st.session_state.model_results,
                                    correlations_dict,
                                    dataset_info
                                )
                                
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è¼‰ PDF å ±å‘Š",
                                    data=pdf_buffer,
                                    file_name=f"prediction_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
                                    mime="application/pdf"
                                )
                                st.success("âœ… PDF å ±å‘Šå·²ç”Ÿæˆ")
                        
                        except Exception as e:
                            st.error(f"âŒ ç”Ÿæˆå ±å‘Šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
            else:
                st.info("è«‹å…ˆè¨“ç·´æ¨¡å‹æˆ–ç¢ºä¿æœ‰æœ‰æ•ˆçš„æ•¸æ“š")

else:
    # é¦–é èªªæ˜
    st.info("ğŸ‘ˆ è«‹å¾å·¦å´æ¬„ä¸Šå‚³æ‚¨çš„æ•¸æ“šæª”æ¡ˆé–‹å§‹ä½¿ç”¨")
    
    st.markdown("""
    ### ğŸ“– ä½¿ç”¨èªªæ˜
    
    1. **ä¸Šå‚³æ•¸æ“šæª”æ¡ˆ**ï¼šæ”¯æ´ CSV æˆ– TXT æ ¼å¼
    2. **æ•¸æ“šæ ¼å¼**ï¼šæ—¥æœŸ,æ™‚é–“,é–‹ç›¤åƒ¹,æœ€é«˜åƒ¹,æœ€ä½åƒ¹,æ”¶ç›¤åƒ¹,æˆäº¤é‡,é æ¸¬1,é æ¸¬2,...,é æ¸¬10
    3. **è‡ªå‹•è­˜åˆ¥**ï¼šç³»çµ±æœƒè‡ªå‹•è­˜åˆ¥æ‚¨çš„é æ¸¬æ¬„ä½ï¼ˆé æ¸¬1åˆ°é æ¸¬10ï¼‰
    4. **ç›¸é—œæ€§åˆ†æ**ï¼šæŸ¥çœ‹æ¯å€‹é æ¸¬å€¼èˆ‡æ”¶ç›¤åƒ¹çš„ç›¸é—œæ€§
    5. **æ¨¡å‹è¨“ç·´**ï¼šé¸æ“‡æ©Ÿå™¨å­¸ç¿’æˆ–ç¥ç¶“ç¶²è·¯æ¨¡å‹é€²è¡Œè¨“ç·´
    6. **æ•ˆèƒ½è©•ä¼°**ï¼šæª¢è¦–æ¨¡å‹çš„é æ¸¬æ•ˆèƒ½æŒ‡æ¨™
    
    ### ğŸ¯ æ”¯æ´çš„æ¨¡å‹
    
    - **å‚³çµ±æ©Ÿå™¨å­¸ç¿’**ï¼šç·šæ€§å›æ­¸ã€éš¨æ©Ÿæ£®æ—ã€XGBoostã€LightGBMã€SVR
    - **ç¥ç¶“ç¶²è·¯**ï¼šå¤šå±¤æ„ŸçŸ¥æ©Ÿ (MLP)ã€é•·çŸ­æœŸè¨˜æ†¶ç¶²è·¯ (LSTM)
    
    ### ğŸ“Š åˆ†æåŠŸèƒ½
    
    - æ•¸æ“šçµ±è¨ˆæè¿°
    - ç¼ºå¤±å€¼åˆ†æ
    - çš®çˆ¾æ£®ç›¸é—œæ€§åˆ†æ
    - ç›¸é—œæ€§ç†±åŠ›åœ–
    - ç‰¹å¾µé‡è¦æ€§åˆ†æ
    - é æ¸¬çµæœè¦–è¦ºåŒ–
    """)

# é å°¾
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>Stock Price Prediction System | Powered by Streamlit</div>",
    unsafe_allow_html=True
)
